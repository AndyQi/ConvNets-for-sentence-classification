{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TREC - Question Answering (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TREC - Question Answering\n",
    "# http://cogcomp.cs.illinois.edu/Data/QA/QC/\n",
    "\n",
    "TREC_Question = namedtuple(\"TREC_Question\", \"label question\")\n",
    "\n",
    "trec_train = set()\n",
    "trec_test = set()\n",
    "\n",
    "for filename in os.listdir(\"TREC/\"):\n",
    "    with open(\"TREC/\"+filename,'r', encoding='latin_1') as f_input:\n",
    "        for line in f_input:\n",
    "            label, question = line.split(' ', 1)\n",
    "            label = label.split(':')[0]\n",
    "            question = TREC_Question(label, question.strip())\n",
    "            if filename=='TREC_10.label':\n",
    "                trec_test.add(question)\n",
    "            else:\n",
    "                trec_train.add(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 5381\n",
      "Test Samples : 500\n",
      "Labels       : {'NUM', 'LOC', 'ABBR', 'HUM', 'DESC', 'ENTY'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Samples: {}\".format(len(trec_train)))\n",
    "print(\"Test Samples : {}\".format(len(trec_test)))\n",
    "print(\"Labels       : {}\".format({x.label for x in trec_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8461 unique tokens.\n",
      "Max. sequence lenght:  33\n",
      "Shape of train data tensor: (5381, 33)\n",
      "Shape of train label tensor: (5381, 6)\n"
     ]
    }
   ],
   "source": [
    "# built two lists with sentences and labels\n",
    "questions_train = [x.question for x in trec_train]\n",
    "labels_train = [x.label for x in trec_train]\n",
    "\n",
    "# convert list of tokens/words to indexes\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(questions_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# get the max sentence lenght, needed for padding\n",
    "max_input_lenght = max([len(x) for x in sequences_train])\n",
    "print(\"Max. sequence lenght: \", max_input_lenght)\n",
    "\n",
    "# pad all the sequences of indexes to the 'max_input_lenght'\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_input_lenght, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels, each must be a vector with dim = num. of possible labels\n",
    "le = LabelEncoder()\n",
    "le.fit(labels_train)\n",
    "labels_encoded_train = le.transform(labels_train)\n",
    "categorical_labels_train = to_categorical(labels_encoded_train, num_classes=None)\n",
    "print('Shape of train data tensor:', data_train.shape)\n",
    "print('Shape of train label tensor:', categorical_labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREC: test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data tensor: (500, 33)\n"
     ]
    }
   ],
   "source": [
    "# pre-process test data\n",
    "questions_test = [x.question for x in trec_test]\n",
    "y_test = [x.label for x in trec_test]\n",
    "sequences_test = tokenizer.texts_to_sequences(questions_test)\n",
    "x_test = pad_sequences(sequences_test, maxlen=max_input_lenght)\n",
    "print('Shape of test data tensor:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convnets_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with random word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = get_cnn_rand(200, len(word_index)+1, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5381/5381 [==============================] - 6s - loss: 0.1099 - acc: 0.9613     \n",
      "Epoch 2/2\n",
      "5381/5381 [==============================] - 7s - loss: 0.0634 - acc: 0.9808     \n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=data_train, y=categorical_labels_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.34      0.95      0.50       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.09      0.26      0.14       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_1.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with pre-trained static word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Matrix shape: (8463, 100)\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = load_embeddings()\n",
    "embeddings_matrix = create_embeddings_matrix(embeddings_index, len(word_index)+1, 100)\n",
    "embedding_layer_static = get_embeddings_layer(embeddings_matrix, 'embedding_layer_static', max_input_lenght, trainable=False)\n",
    "model_2 = get_cnn_pre_trained_embeddings(embedding_layer_static, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5381/5381 [==============================] - 2s - loss: 0.3754 - acc: 0.8452     \n",
      "Epoch 2/2\n",
      "5381/5381 [==============================] - 1s - loss: 0.2528 - acc: 0.8980     \n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x=data_train, y=categorical_labels_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_2.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with pre-trained dynamic word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer_dynamic = get_embeddings_layer(embeddings_matrix, 'embedding_layer_dynamic', max_input_lenght, trainable=True)\n",
    "model_3 = get_cnn_pre_trained_embeddings(embedding_layer_dynamic, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5381/5381 [==============================] - 3s - loss: 0.3538 - acc: 0.8554     \n",
      "Epoch 2/2\n",
      "5381/5381 [==============================] - 3s - loss: 0.2104 - acc: 0.9154     \n"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(x=data_train, y=categorical_labels_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.29      0.98      0.44       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.27      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_3.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN multichanell with pre-trained dynamic and static word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4 = get_cnn_multichannel(embedding_layer_static, embedding_layer_dynamic, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5381/5381 [==============================] - 5s - loss: 0.2949 - acc: 0.8804     \n",
      "Epoch 2/2\n",
      "5381/5381 [==============================] - 5s - loss: 0.1482 - acc: 0.9439     \n"
     ]
    }
   ],
   "source": [
    "history = model_4.fit(x=[data_train, data_train], y=categorical_labels_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_4.predict([x_test, x_test])\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
