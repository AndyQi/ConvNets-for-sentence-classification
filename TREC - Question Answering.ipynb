{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TREC - Question Answering (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TREC - Question Answering\n",
    "# http://cogcomp.cs.illinois.edu/Data/QA/QC/\n",
    "\n",
    "TREC_Question = namedtuple(\"TREC_Question\", \"label question\")\n",
    "\n",
    "trec_train = set()\n",
    "trec_test = set()\n",
    "\n",
    "for filename in os.listdir(\"TREC/\"):\n",
    "    with open(\"TREC/\"+filename,'r', encoding='latin_1') as f_input:\n",
    "        for line in f_input:\n",
    "            label, question = line.split(' ', 1)\n",
    "            label = label.split(':')[0]\n",
    "            question = TREC_Question(label, question.strip())\n",
    "            if filename=='TREC_10.label':\n",
    "                trec_test.add(question)\n",
    "            else:\n",
    "                trec_train.add(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 5381\n",
      "Test Samples : 500\n",
      "Labels       : {'ABBR', 'NUM', 'ENTY', 'LOC', 'DESC', 'HUM'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Samples: {}\".format(len(trec_train)))\n",
    "print(\"Test Samples : {}\".format(len(trec_test)))\n",
    "print(\"Labels       : {}\".format({x.label for x in trec_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8461 unique tokens.\n",
      "Max. sequence lenght:  33\n",
      "Shape of train data tensor: (5381, 33)\n",
      "Shape of train label tensor: (5381, 6)\n"
     ]
    }
   ],
   "source": [
    "# built two lists with sentences and labels\n",
    "questions_train = [x.question for x in trec_train]\n",
    "labels_train = [x.label for x in trec_train]\n",
    "\n",
    "# convert list of tokens/words to indexes\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(questions_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# get the max sentence lenght, needed for padding\n",
    "max_input_lenght = max([len(x) for x in sequences_train])\n",
    "print(\"Max. sequence lenght: \", max_input_lenght)\n",
    "\n",
    "# pad all the sequences of indexes to the 'max_input_lenght'\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_input_lenght, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels, each must be a vector with dim = num. of possible labels\n",
    "le = LabelEncoder()\n",
    "le.fit(labels_train)\n",
    "labels_encoded_train = le.transform(labels_train)\n",
    "categorical_labels_train = to_categorical(labels_encoded_train, num_classes=None)\n",
    "print('Shape of train data tensor:', data_train.shape)\n",
    "print('Shape of train label tensor:', categorical_labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREC: test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data tensor: (500, 33)\n",
      "Shape of test labels tensor: (500, 6)\n"
     ]
    }
   ],
   "source": [
    "# pre-process test data\n",
    "questions_test = [x.question for x in trec_test]\n",
    "y_test = [x.label for x in trec_test]\n",
    "sequences_test = tokenizer.texts_to_sequences(questions_test)\n",
    "x_test = pad_sequences(sequences_test, maxlen=max_input_lenght)\n",
    "\n",
    "labels_encoded_test = le.transform(y_test)\n",
    "categorical_labels_test = to_categorical(labels_encoded_test, num_classes=None)\n",
    "print('Shape of test data tensor:', x_test.shape)\n",
    "print('Shape of test labels tensor:', categorical_labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convnets_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with random word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = get_cnn_rand(300, len(word_index)+1, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5381/5381 [==============================] - 8s - loss: 0.4278 - acc: 0.8275     \n",
      "Epoch 2/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.3234 - acc: 0.8676     \n",
      "Epoch 3/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.2484 - acc: 0.8983     \n",
      "Epoch 4/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.1980 - acc: 0.9200     - ETA: 0s - loss: 0.1981 - acc: 0.91\n",
      "Epoch 5/10\n",
      "5381/5381 [==============================] - 11s - loss: 0.1560 - acc: 0.9408    \n",
      "Epoch 6/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.1252 - acc: 0.9528     \n",
      "Epoch 7/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.0962 - acc: 0.9664     \n",
      "Epoch 8/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.0751 - acc: 0.9753     \n",
      "Epoch 9/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.0570 - acc: 0.9825     \n",
      "Epoch 10/10\n",
      "5381/5381 [==============================] - 9s - loss: 0.0479 - acc: 0.9853     \n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=data_train, y=categorical_labels_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75866664552688601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model_1.evaluate(x_test, categorical_labels_test, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_1.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with pre-trained static word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Matrix shape: (8462, 100)\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = load_fasttext_embeddings()\n",
    "embeddings_matrix = create_embeddings_matrix(embeddings_index, word_index, 100)\n",
    "embedding_layer_static = get_embeddings_layer(embeddings_matrix, 'embedding_layer_static', max_input_lenght, trainable=False)\n",
    "model_2 = get_cnn_pre_trained_embeddings(embedding_layer_static, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.3811 - acc: 0.8440     \n",
      "Epoch 2/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.2569 - acc: 0.8973     \n",
      "Epoch 3/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.2083 - acc: 0.9152     \n",
      "Epoch 4/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.1735 - acc: 0.9315     \n",
      "Epoch 5/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.1450 - acc: 0.9442     \n",
      "Epoch 6/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.1158 - acc: 0.9594     \n",
      "Epoch 7/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.0905 - acc: 0.9714     \n",
      "Epoch 8/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.0705 - acc: 0.9807     \n",
      "Epoch 9/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.0525 - acc: 0.9881     \n",
      "Epoch 10/10\n",
      "5381/5381 [==============================] - 1s - loss: 0.0392 - acc: 0.9933     \n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x=data_train, y=categorical_labels_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76133331680297855"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model_2.evaluate(x_test, categorical_labels_test, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_2.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with pre-trained dynamic word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer_dynamic = get_embeddings_layer(embeddings_matrix, 'embedding_layer_dynamic', max_input_lenght, trainable=True)\n",
    "model_3 = get_cnn_pre_trained_embeddings(embedding_layer_dynamic, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.3718 - acc: 0.8478     \n",
      "Epoch 2/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.2277 - acc: 0.9084     \n",
      "Epoch 3/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.1572 - acc: 0.9387     \n",
      "Epoch 4/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.1059 - acc: 0.9617     \n",
      "Epoch 5/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0637 - acc: 0.9808     \n",
      "Epoch 6/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0368 - acc: 0.9904     \n",
      "Epoch 7/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0204 - acc: 0.9958     \n",
      "Epoch 8/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0113 - acc: 0.9984     \n",
      "Epoch 9/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0064 - acc: 0.9993     \n",
      "Epoch 10/10\n",
      "5381/5381 [==============================] - 3s - loss: 0.0040 - acc: 0.9998     \n"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(x=data_train, y=categorical_labels_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75866664552688601"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model_3.evaluate(x_test, categorical_labels_test, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_3.predict(x_test)\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN multichanell with pre-trained dynamic and static word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4 = get_cnn_multichannel(embedding_layer_static, embedding_layer_dynamic, max_input_lenght, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5381/5381 [==============================] - 4s - loss: 0.0296 - acc: 0.9925     \n",
      "Epoch 2/10\n",
      "5381/5381 [==============================] - 4s - loss: 0.0145 - acc: 0.9974     \n",
      "Epoch 3/10\n",
      "5381/5381 [==============================] - 4s - loss: 0.0072 - acc: 0.9991     \n",
      "Epoch 4/10\n",
      "5381/5381 [==============================] - 4s - loss: 0.0037 - acc: 0.9998     \n",
      "Epoch 5/10\n",
      "5381/5381 [==============================] - 5s - loss: 0.0021 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "5381/5381 [==============================] - 5s - loss: 0.0014 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "5381/5381 [==============================] - 5s - loss: 9.4511e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "5381/5381 [==============================] - 5s - loss: 7.0011e-04 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "5381/5381 [==============================] - 5s - loss: 5.1368e-04 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "5381/5381 [==============================] - 5s - loss: 3.9920e-04 - acc: 1.0000     \n"
     ]
    }
   ],
   "source": [
    "history = model_4.fit(x=[data_train, data_train], y=categorical_labels_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7589999799728393"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model_4.evaluate(x=[x_test,x_test], y=categorical_labels_test, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.00      0.00      0.00         9\n",
      "       DESC       0.28      1.00      0.43       138\n",
      "       ENTY       0.00      0.00      0.00        94\n",
      "        HUM       0.00      0.00      0.00        65\n",
      "        LOC       0.00      0.00      0.00        81\n",
      "        NUM       0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       0.08      0.28      0.12       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model_4.predict([x_test, x_test])\n",
    "class_predictions = [np.argmax(x) for x in raw_predictions]\n",
    "print(classification_report(y_test, le.inverse_transform(class_predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
